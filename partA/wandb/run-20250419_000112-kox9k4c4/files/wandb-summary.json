{"_wandb":{"runtime":46},"Test Accuracy":9.375,"_timestamp":1.7450011186364381e+09,"_runtime":46.033307982,"_step":1,"Test Predictions Table (10x3 Grid)":{"sha256":"e17de8c6091ed333c67971b90a94025c3ca30e378c7d3f3087c82dbd1746e00a","size":1173,"artifact_path":"wandb-client-artifact://e8xur1zp1xgday19h53gnbvi9emcn2cfax2i5s7ei31m4cxgh9iy3yivbhjhkub4qd3a9xuca8trx2zpkjllm4u2rbxt2a0j8ol3hpdaflknj6d031h9lureit7s3cc3/Test Predictions Table (10x3 Grid).table.json","_latest_artifact_path":"wandb-client-artifact://oycmtapd8vupo60i56xu5dh567de51dhwqkr5xejfpf7677ebpv5bmsjsdc3ozkt1fkku3taa58by38u9ve7hcvbn7iq6qctfw1ur1jzzm42usx7h38iehy0o3mb0316:latest/Test Predictions Table (10x3 Grid).table.json","path":"media/table/Test Predictions Table (10x3 Grid)_1_e17de8c6091ed333c679.table.json","ncols":4,"nrows":30,"_type":"table-file"}}